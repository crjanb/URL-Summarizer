{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6929c9fd-a5cd-42bc-8340-2713a8332991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1a89ae9b-f932-43f4-ae91-817baa63ac2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install unstructured libmagic python-magic python-magic-bin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a06a880-06ba-4c0b-898f-7b2f8bdb7e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install -U langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d6a12ec-bf60-4c72-8689-4d7a5fa89aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install langchain langchain-ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47004c1e-f517-45e3-8acf-62ce35534942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc7fdf76-2a2c-4dc2-9b77-e6b5b73b1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e18a80ff-3fbe-4322-9b54-ddc6f8738388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52ac6889-c066-4ad8-8bd1-cc64d047d382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install faiss-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6f0562b-bb90-4f24-b615-d968677151bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b70b685b-3c36-4735-b9df-145b3da3a39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pickle\n",
    "import langchain\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.chains import RetrievalQAWithSourcesChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.document_loaders import UnstructuredURLLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ee1b986-8e10-4247-91a7-ba7d25c6e94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "# Access the token\n",
    "api_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c9d38af4-da9d-4fb4-a9c2-a302b3d47845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Hugging Face Hub API token if needed\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = api_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9ae5adc1-ca68-40df-9ba9-de4edee3f3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crjan\\AppData\\Local\\Temp\\ipykernel_132\\1783131309.py:2: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEndpoint``.\n",
      "  llm = HuggingFaceHub(\n",
      "E:\\Projects\\2024-25\\URL_Summarizer\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Initialize the Hugging Face LLM using a hosted model (e.g., Falcon 7B)\n",
    "llm = HuggingFaceHub(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\", #change the model accordingly\n",
    "    model_kwargs={\"temperature\": 0.9, \"max_new_tokens\": 500}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7546ea62-287d-4368-8c5c-7592aa8db069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents loaded: 2\n"
     ]
    }
   ],
   "source": [
    "# (1) Load data\n",
    "loaders = UnstructuredURLLoader(urls=[\n",
    "    \"https://www.datacamp.com/blog/manus-ai\",\n",
    "    \"https://medium.com/@vsinha027/chinas-manus-ai-d4ccafc2affd\"\n",
    "])\n",
    "data = loaders.load()\n",
    "print(f\"Number of documents loaded: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55eea912-8e67-481a-bd1d-3cc66d6eded7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document chunks: 6\n"
     ]
    }
   ],
   "source": [
    "# (2) Split data into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(data)\n",
    "print(f\"Number of document chunks: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60436de5-aa6a-4302-8db6-4d9bae508736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crjan\\AppData\\Local\\Temp\\ipykernel_132\\2174174291.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "E:\\Projects\\2024-25\\URL_Summarizer\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\crjan\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "# (3) Create embeddings using HuggingFaceEmbeddings and build a FAISS index\n",
    "# Here we use the free, open-source \"all-MiniLM-L6-v2\" model for embeddings.\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorindex = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# Save the FAISS vector index locally for reuse\n",
    "file_path = \"vector_index_new.pkl\"\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(vectorindex, f)\n",
    "\n",
    "# Optionally, load the vector index if it already exists\n",
    "if os.path.exists(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        vectorindex = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec242e7-46e3-4886-b1ae-d97df8c92564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\crjan\\AppData\\Local\\Temp\\ipykernel_132\\4183674248.py:8: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain({\"question\": query}, return_only_outputs=True)\n",
      "E:\\Projects\\2024-25\\URL_Summarizer\\venv\\Lib\\site-packages\\huggingface_hub\\utils\\_deprecation.py:131: FutureWarning: 'post' (from 'huggingface_hub.inference._client') is deprecated and will be removed from version '0.31.0'. Making direct POST requests to the inference server is not supported anymore. Please use task methods instead (e.g. `InferenceClient.chat_completion`). If your use case is not supported, please open an issue in https://github.com/huggingface/huggingface_hub.\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"What is manus AI?\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input_list\": [\n",
      "    {\n",
      "      \"context\": \"Introduction to Manus.AI\\n\\nManus, derived from the Latin word for “hand”, is a general AI agent that turns your thoughts into actions\\n\\nManus AI is China’s latest large language model (LLM), and it’s already shaking up the AI landscape. Developed by Monica, a rising AI company, Manus AI is being positioned as a serious competitor to OpenAI’s ChatGPT-4.5 and Google’s Gemini models. But what makes it special?\",\n",
      "      \"question\": \"What is manus AI?\"\n",
      "    },\n",
      "    {\n",
      "      \"context\": \"Vivek Sinha, PhD\\n\\nFollow\\n\\nPublished in\\n\\nLevel Up Coding\\n\\n8 min read\\n\\nMar 11, 2025\\n\\n--\\n\\nEverything You Need to Know About Manus AI — China’s Latest AI Disruptor\",\n",
      "      \"question\": \"What is manus AI?\"\n",
      "    },\n",
      "    {\n",
      "      \"context\": \"Unlike conventional AI chatbots, Manus AI is being designed as a next-generation AI agent, capable of independent reasoning and decision-making. It goes beyond just generating text — it’s built to take action, automate tasks, and execute multi-step…\\n\\n--\\n\\n--\\n\\nLevel Up Coding\\n\\nLevel Up Coding\\n\\nFollow\\n\\nPublished in Level Up Coding\\n\\n216K Followers\\n\\nLast published 16 hours ago\\n\\nCoding tutorials and news. The developer homepage gitconnected.com && skilled.dev && levelup.dev\\n\\nFollow\\n\\nVivek Sinha, PhD\",\n",
      "      \"question\": \"What is manus AI?\"\n",
      "    },\n",
      "    {\n",
      "      \"context\": \"Mar 11, 2025\\n\\n--\\n\\nEverything You Need to Know About Manus AI — China’s Latest AI Disruptor\\n\\nManus AI is the new talk on the LLM block. Built by Monica AI, this Chinese large language model (LLM) is making big claims — faster, smarter, and cheaper than the competition. OpenAI has ChatGPT-4.5, Google has Gemini, Anthropic has Claude… and now, China has Manus coming after DeepSeek. But what’s the big deal? Why is everyone suddenly paying attention?\\n\\nIntroduction to Manus.AI\",\n",
      "      \"question\": \"What is manus AI?\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nIntroduction to Manus.AI\\n\\nManus, derived from the Latin word for “hand”, is a general AI agent that turns your thoughts into actions\\n\\nManus AI is China’s latest large language model (LLM), and it’s already shaking up the AI landscape. Developed by Monica, a rising AI company, Manus AI is being positioned as a serious competitor to OpenAI’s ChatGPT-4.5 and Google’s Gemini models. But what makes it special?\\nQuestion: What is manus AI?\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nVivek Sinha, PhD\\n\\nFollow\\n\\nPublished in\\n\\nLevel Up Coding\\n\\n8 min read\\n\\nMar 11, 2025\\n\\n--\\n\\nEverything You Need to Know About Manus AI — China’s Latest AI Disruptor\\nQuestion: What is manus AI?\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nUnlike conventional AI chatbots, Manus AI is being designed as a next-generation AI agent, capable of independent reasoning and decision-making. It goes beyond just generating text — it’s built to take action, automate tasks, and execute multi-step…\\n\\n--\\n\\n--\\n\\nLevel Up Coding\\n\\nLevel Up Coding\\n\\nFollow\\n\\nPublished in Level Up Coding\\n\\n216K Followers\\n\\nLast published 16 hours ago\\n\\nCoding tutorials and news. The developer homepage gitconnected.com && skilled.dev && levelup.dev\\n\\nFollow\\n\\nVivek Sinha, PhD\\nQuestion: What is manus AI?\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[chain:RetrievalQAWithSourcesChain > chain:MapReduceDocumentsChain > chain:LLMChain > llm:HuggingFaceHub] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Use the following portion of a long document to see if any of the text is relevant to answer the question. \\nReturn any relevant text verbatim.\\nMar 11, 2025\\n\\n--\\n\\nEverything You Need to Know About Manus AI — China’s Latest AI Disruptor\\n\\nManus AI is the new talk on the LLM block. Built by Monica AI, this Chinese large language model (LLM) is making big claims — faster, smarter, and cheaper than the competition. OpenAI has ChatGPT-4.5, Google has Gemini, Anthropic has Claude… and now, China has Manus coming after DeepSeek. But what’s the big deal? Why is everyone suddenly paying attention?\\n\\nIntroduction to Manus.AI\\nQuestion: What is manus AI?\\nRelevant text, if any:\"\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# (4) Retrieve similar documents for a given query and generate an answer using Llama 3\n",
    "chain = RetrievalQAWithSourcesChain.from_llm(llm=llm, retriever=vectorindex.as_retriever())\n",
    "\n",
    "query = \"What is manus AI?\"\n",
    "\n",
    "langchain.debug = True\n",
    "\n",
    "chain({\"question\": query}, return_only_outputs=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6446fe4-860e-4b7b-8dbb-b40049ef8cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84910e25-86ef-4394-973a-74039955321f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
